{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19f4b11b",
   "metadata": {},
   "source": [
    "# LR parser\n",
    "LR parser is a bottom-up parser that can parse context-free languages in linear time,\n",
    "i.e. it reads input tokens, contatenates them into AST nodes in hope to build tree at the end.\n",
    "This notebook contains an implementation of LR(0) parser according to the Dragon Book."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f8b6c5",
   "metadata": {},
   "source": [
    "### Source context-free grammar\n",
    "I use this CFG as example(I took it from [wikipedia](https://en.wikipedia.org/wiki/LR_parser#Additional_example_1+1)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4743bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_source = \"\"\"\n",
    "    E → E * B\n",
    "    E → E + B\n",
    "    E → B\n",
    "    B → 0\n",
    "    B → 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb8fa2b",
   "metadata": {},
   "source": [
    "This context-free grammar desribes context-free language that contains these sentences/words:\n",
    "    \n",
    "    0, 1, 0*1, 1+0, 1*1, 0+0, 1+1*1, 1+0*0+1+0*0*0*1\n",
    "It is ok to change the `grammar_source` to another grammar: the code will handle it correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a494bc1",
   "metadata": {},
   "source": [
    "### Parse rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f113b1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E → E * B\n",
      "E → E + B\n",
      "E → B\n",
      "B → 0\n",
      "B → 1\n"
     ]
    }
   ],
   "source": [
    "def parse_rules(source):\n",
    "    rules = []\n",
    "    for rule in source.strip().split(\"\\n\"):\n",
    "        variable, body = rule.strip().split(\" → \")\n",
    "        rules.append((variable, tuple(body.split(\" \"))))\n",
    "    return rules\n",
    "rules = parse_rules(grammar_source)\n",
    "print(\"\\n\".join(f\"{variable} → {' '.join(body)}\" for variable, body in rules))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9013f9",
   "metadata": {},
   "source": [
    "### Derive variables, terminals, start symbol from rules\n",
    "Mathematically speaking we [should](https://en.wikipedia.org/wiki/Context-free_grammar#Formal_definitions) specify variables, terminals, rules and start symbol in order to call it a grammar,\n",
    "but I too lazy for that. So instead I wrote a function `derive_symbols()` to derive all these things from rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08d7361d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables={'B', 'E'}\n",
      "terminals={'+', '0', '*', '1'}\n",
      "start='E'\n"
     ]
    }
   ],
   "source": [
    "def derive_symbols(rules):\n",
    "    symbols = set()\n",
    "    for variable, body in rules:\n",
    "        symbols.add(variable)\n",
    "        symbols.update(set(body))\n",
    "    variables = {variable for variable, body in rules}\n",
    "    terminals = symbols - variables\n",
    "    start = rules[0][0]\n",
    "    return variables, terminals, start\n",
    "variables, terminals, start = derive_symbols(rules)\n",
    "print(f\"{variables=}\\n{terminals=}\\n{start=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e999fe3a",
   "metadata": {},
   "source": [
    "On second thought I am too lazy to bring all four variables(variables, terminals, rules, start) everywhere,\n",
    "so it makes sence to implement the `Grammar` class according to its [mathematical definition](https://en.wikipedia.org/wiki/Context-free_grammar#Formal_definitions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df775cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start symbol: E\n",
      "variables: B, E\n",
      "terminals: '+', '0', '*', '1'\n",
      "rules:\tE → E * B\n",
      "\tE → E + B\n",
      "\tE → B\n",
      "\tB → 0\n",
      "\tB → 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import dataclasses\n",
    "@dataclasses.dataclass(frozen=True)\n",
    "class Grammar:\n",
    "    variables: set[str]\n",
    "    terminals: set[str]\n",
    "    rules: list[(str, tuple[str])]\n",
    "    start: str\n",
    "        \n",
    "    def __str__(self):\n",
    "        s = \"start symbol: \" + self.start + \"\\n\"\n",
    "        s += \"variables: \" + \", \".join(map(str, self.variables)) + \"\\n\"\n",
    "        s += \"terminals: \" + \", \".join(map(repr, self.terminals)) + \"\\n\"\n",
    "        rules = [f\"{var} → {' '.join(body)}\" for var, body in self.rules]\n",
    "        return s + \"rules:\\t\" + \"\\n\\t\".join(rules) + \"\\n\"\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return id(self)\n",
    "grammar = Grammar(variables, terminals, rules, start)\n",
    "print(grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b13998",
   "metadata": {},
   "source": [
    "### LR(0) Items\n",
    "LR(0) items are just rules with dot in body, e.g. `E → E •+ B`, `E → •B`, `B → 0•`.\n",
    "Items indicate that the parser has recognized a string correspondig to the part of rule before the dot,\n",
    "e.g. `E → E * •B` means that the parser has recognize `E` and `*` on the input and now expects to read `B`.\n",
    "\n",
    "I decided to make a class `Item`. It's absolutely not necessary and\n",
    "it's only purpose is to nicely print the item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38e1c6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item(variable='V', body=('A', 'B', 'C', 'D'), dot_position=2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dataclasses\n",
    "@dataclasses.dataclass(frozen=True, order=True)\n",
    "class Item:\n",
    "    variable: str\n",
    "    body: tuple[str]\n",
    "    dot_position: int\n",
    "    \n",
    "    def __str__(self):\n",
    "        body = list(self.body)\n",
    "        if self.dot_position == len(body):\n",
    "            return f\"{self.variable} → {' '.join(self.body)}\" + \"•\"\n",
    "        body[self.dot_position] = \"•\" + body[self.dot_position]\n",
    "        return f\"{self.variable} → {' '.join(body)}\"         \n",
    "    \n",
    "    @staticmethod\n",
    "    def from_str(s):\n",
    "        variable, body = s.strip().split(\" → \")\n",
    "        body = body.split(\" \")\n",
    "        for dot_position, symbol in enumerate(body + [\"•\"]):\n",
    "            if symbol.startswith(\"•\"):\n",
    "                break\n",
    "        body = tuple(symbol.strip(\"•\") for symbol in body)\n",
    "        return Item(variable, body, dot_position)\n",
    "    \n",
    "    @property\n",
    "    def next_symbol(self):\n",
    "        if self.dot_position == len(self.body):\n",
    "            return None\n",
    "        return self.body[self.dot_position]\n",
    "    \n",
    "\n",
    "Item.from_str(\"V → A B •C D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055a8160",
   "metadata": {},
   "source": [
    "### Closure of items\n",
    "Closure of a set of items is the set combined with items that can be obtained\n",
    "by pushing dot from variable into the body of a rule with that variable in its head,\n",
    "e.g. `closure {E → •B} = {E → •B, B → •0, B → •1}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ebfab3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B → •0\n",
      "B → •1\n",
      "E → E * •B\n"
     ]
    }
   ],
   "source": [
    "def closure(grammar, items):\n",
    "    rules = grammar.rules\n",
    "    new_items = set()\n",
    "    for item in items:\n",
    "        variable = item.next_symbol\n",
    "        if variable not in grammar.variables:\n",
    "            continue\n",
    "        for head, body in filter(lambda rule: rule[0] == variable, rules):\n",
    "            new_item = Item(head, body, 0)\n",
    "            if new_item not in items:\n",
    "                new_items.add(new_item)\n",
    "    return closure(grammar, items | new_items) if new_items else items\n",
    "                    \n",
    "for item in sorted(closure(grammar, {Item.from_str(\"E → E * •B\")})):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77daa465",
   "metadata": {},
   "source": [
    "### States (sets of items)\n",
    "The core idea of LR parser is that its states are just sets of possible items.\n",
    "When parser have already read something from input, it doesn't \"know\" yet what\n",
    "rule he is going to apply and what AST node he is going to build,\n",
    "but he does know what items correspond to already read symbols.\n",
    "Actually all possible items corresponding to some state fully specify this state.\n",
    "And the set of all possible sets of items is finite.\n",
    "Thus number of states is finite.\n",
    "And we are going to precompute all the states!\n",
    "\n",
    "With purpose of saving memory a set of items can be represented by items that\n",
    "can't be computed as closure of other items in this set.\n",
    "For example set {`E → E * •B`, `B → •1`, `B → •0`} can be represented by item\n",
    "`E → E * •B` alone.\n",
    "Here is class `ItemSet` that implements such representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7cf5610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item set {B → •0, B → •1, E → E * •B} has kernel items E → E * •B\n"
     ]
    }
   ],
   "source": [
    "@dataclasses.dataclass(frozen=True)\n",
    "class ItemSet:\n",
    "    kernel_items: frozenset[Item]\n",
    "    domain: Grammar\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_items(grammar, items):\n",
    "        # I assume items can be generated by closure() if they have dot at the\n",
    "        # begining of the body.\n",
    "        # It is not true in general case, but sufficient for LR parser states\n",
    "        kernel_items = filter(lambda item: item.dot_position > 0, items)\n",
    "        kernel_items = frozenset(kernel_items)\n",
    "        return ItemSet(kernel_items, grammar)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        yield from closure(self.domain, self.kernel_items)\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"{\" + \", \".join(sorted(map(str, self))) + \"}\"\n",
    "\n",
    "    def __bool__(self):\n",
    "        return bool(self.kernel_items)\n",
    "\n",
    "items = \"E → E * •B, B → •1, B → •0\".split(\", \")\n",
    "s = ItemSet.from_items(grammar, map(Item.from_str, items))\n",
    "print(\"Item set\", s, \"has kernel items\", \", \".join(map(str, s.kernel_items)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a5d733",
   "metadata": {},
   "source": [
    "### GOTO\n",
    "\n",
    "    GOTO(current_parser_state, next_symbol) -> next_parser_state\n",
    " \n",
    "The GOTO function computes next parser state(item set)\n",
    "based on its current state(item set).\n",
    "Since a state is just a set of items, the function is pretty straightforward:\n",
    "assuming `next_symbol=Y` for every item `W → X •Y Z` from current set of items\n",
    "add `W → X Y• Z` into the next state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fc03be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goto({B → •0, B → •1, E → E * •B}, \"1\")  =  {B → 1•}\n"
     ]
    }
   ],
   "source": [
    "def goto(grammar, items, next_symbol):\n",
    "    next_items = set()\n",
    "    for item in items:\n",
    "        if item.next_symbol == next_symbol:\n",
    "            next_item = Item(item.variable, item.body, item.dot_position + 1)\n",
    "            next_items.add(next_item)\n",
    "    return ItemSet.from_items(grammar, next_items)\n",
    "print(f'goto({s}, \"1\")  = ', goto(grammar, s, \"1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fbd865",
   "metadata": {},
   "source": [
    "### The states precomputed\n",
    "We can use the functoin `goto()` to precompute all reachable states of parser.\n",
    "With this purpose in mind we will need a starting state, a starting item.\n",
    "We need a rule that will contain a starting symbol in its body.\n",
    "So we augment our grammar with such a rule:\n",
    "we add new start symbol `START` and new rule `START → $ OLD_START $`,\n",
    "where `$` denotes start or end of input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17ec0e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start symbol: START\n",
      "variables: B, E, START\n",
      "terminals: '$', '0', '1', '+', '*'\n",
      "rules:\tSTART → $ E $\n",
      "\tE → E * B\n",
      "\tE → E + B\n",
      "\tE → B\n",
      "\tB → 0\n",
      "\tB → 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def augment_grammar(grammar):\n",
    "    variables, rules, start = grammar.variables, grammar.rules, grammar.start\n",
    "    new_start = \"START\"\n",
    "    # if variable START is already in the grammar, we use START' or START'' ...\n",
    "    while new_start in variables:\n",
    "        new_start += \"'\"\n",
    "    new_variables = variables | {new_start}\n",
    "    new_terminals = grammar.terminals | {\"$\"}\n",
    "    new_rules = [(new_start, (\"$\", start, \"$\"))] + rules\n",
    "    return Grammar(new_variables, new_terminals, new_rules, new_start)\n",
    "augmented_grammar = augment_grammar(grammar)\n",
    "print(augmented_grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7659491f",
   "metadata": {},
   "source": [
    "Now we can precompute all the states that are reachable from item `START → $ •OLD_START $`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c73cda74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1: {B → •0, B → •1, E → •B, E → •E * B, E → •E + B, START → $ •E $}\n",
      " 2: {B → 0•}\n",
      " 3: {E → B•}\n",
      " 4: {E → E •* B, E → E •+ B, START → $ E •$}\n",
      " 5: {B → 1•}\n",
      " 6: {B → •0, B → •1, E → E + •B}\n",
      " 7: {START → $ E $•}\n",
      " 8: {B → •0, B → •1, E → E * •B}\n",
      " 9: {E → E + B•}\n",
      "10: {E → E * B•}\n"
     ]
    }
   ],
   "source": [
    "def grammar_states(grammar):\n",
    "    assert grammar.rules[0][0] == grammar.start\n",
    "    variables, rules, start = grammar.variables, grammar.rules, grammar.start\n",
    "    symbols = grammar.variables | grammar.terminals\n",
    "    start_state = ItemSet.from_items(grammar, {Item(*rules[0], 1)})\n",
    "    states = [start_state]\n",
    "    states_lookup = {start_state}\n",
    "    processed_states = 0\n",
    "    while processed_states < len(states):\n",
    "        state = states[processed_states]\n",
    "        processed_states += 1\n",
    "        for symbol in symbols:\n",
    "            new_state = goto(grammar, state, symbol)\n",
    "            if new_state and new_state not in states_lookup:\n",
    "                states_lookup.add(new_state)\n",
    "                states.append(new_state)\n",
    "    return states\n",
    "\n",
    "states = grammar_states(augmented_grammar)\n",
    "for i, state in enumerate(states, 1):\n",
    "    print(f\"{i:2}: {state}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8855a9b",
   "metadata": {},
   "source": [
    "### Actions precomputed\n",
    "We have states precomputed. Cool! Now let's precompute actions that should be executed.\n",
    "For each possible state and each posible terminal on input we will compute desired action.\n",
    "\n",
    "LR parser supports these types of actions:\n",
    "1. SHIFT: push the terminal from input into the stack.\n",
    "2. REDUCE: pack a few symbols from stack into an AST node.\n",
    "3. ACCEPT: accept current stack as succesfully built AST tree. \n",
    "4. DIE: raise an exception if there is no reasanable action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cf6b5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 '$' -> die START \t {B → •0, B → •1, E → •B, E → •E * B, E → •E + B, START → $ •E $}\n",
      "0 '0' -> shift 1 \t {B → •0, B → •1, E → •B, E → •E * B, E → •E + B, START → $ •E $}\n",
      "0 '1' -> shift 4 \t {B → •0, B → •1, E → •B, E → •E * B, E → •E + B, START → $ •E $}\n",
      "0 '+' -> die START \t {B → •0, B → •1, E → •B, E → •E * B, E → •E + B, START → $ •E $}\n",
      "0 '*' -> die START \t {B → •0, B → •1, E → •B, E → •E * B, E → •E + B, START → $ •E $}\n",
      "1 '$' -> reduce B 1 \t {B → 0•}\n",
      "1 '0' -> reduce B 1 \t {B → 0•}\n",
      "1 '1' -> reduce B 1 \t {B → 0•}\n",
      "1 '+' -> reduce B 1 \t {B → 0•}\n",
      "1 '*' -> reduce B 1 \t {B → 0•}\n",
      "2 '$' -> reduce E 1 \t {E → B•}\n",
      "2 '0' -> reduce E 1 \t {E → B•}\n",
      "2 '1' -> reduce E 1 \t {E → B•}\n",
      "2 '+' -> reduce E 1 \t {E → B•}\n",
      "2 '*' -> reduce E 1 \t {E → B•}\n",
      "3 '$' -> accept E \t {E → E •* B, E → E •+ B, START → $ E •$}\n",
      "3 '0' -> die E \t {E → E •* B, E → E •+ B, START → $ E •$}\n",
      "3 '1' -> die E \t {E → E •* B, E → E •+ B, START → $ E •$}\n",
      "3 '+' -> shift 5 \t {E → E •* B, E → E •+ B, START → $ E •$}\n",
      "3 '*' -> shift 7 \t {E → E •* B, E → E •+ B, START → $ E •$}\n",
      "4 '$' -> reduce B 1 \t {B → 1•}\n",
      "4 '0' -> reduce B 1 \t {B → 1•}\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "def precompute_actions(grammar):\n",
    "    states = grammar_states(grammar)\n",
    "    actions = {}\n",
    "    for i, state in enumerate(states):\n",
    "        kernel_item = next(iter(state.kernel_items))\n",
    "        variable, body = kernel_item.variable, kernel_item.body\n",
    "        for next_terminal in grammar.terminals:\n",
    "            actions[i, next_terminal] = (\"die\", variable)\n",
    "        for next_terminal in grammar.terminals - {'$'}:\n",
    "            next_state = goto(grammar, state, next_terminal)\n",
    "            if next_state:\n",
    "                actions[i, next_terminal] = (\"shift\", states.index(next_state))\n",
    "        if any(i.variable == grammar.start and i.dot_position == 2 for i in state.kernel_items):\n",
    "            actions[i, \"$\"] = (\"accept\", variable)\n",
    "        if kernel_item.dot_position == len(kernel_item.body):\n",
    "            for next_terminal in grammar.terminals:\n",
    "                actions[i, next_terminal] = (\"reduce\", variable, len(body))\n",
    "    return actions\n",
    "\n",
    "actions = precompute_actions(augmented_grammar)\n",
    "for situation, action in list(actions.items())[:22]:\n",
    "    state_index, terminal = situation\n",
    "    print(state_index, repr(terminal), \"->\", *action, \"\\t\", states[state_index])\n",
    "if len(actions) > 22: print(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfe62acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- '$' '*' '+' '0' '1'\n",
      " 0 dST dST dST s1  s4  \t {B → •0, B → •1, E → •B, E → •E * B, E → •E + B, START → $ •E $}\n",
      " 1 rB  rB  rB  rB  rB  \t {B → 0•}\n",
      " 2 rE  rE  rE  rE  rE  \t {E → B•}\n",
      " 3 aE  s7  s5  dE  dE  \t {E → E •* B, E → E •+ B, START → $ E •$}\n",
      " 4 rB  rB  rB  rB  rB  \t {B → 1•}\n",
      " 5 dE  dE  dE  s1  s4  \t {B → •0, B → •1, E → E + •B}\n",
      " 6 rST rST rST rST rST \t {START → $ E $•}\n",
      " 7 dE  dE  dE  s1  s4  \t {B → •0, B → •1, E → E * •B}\n",
      " 8 rE  rE  rE  rE  rE  \t {E → E + B•}\n",
      " 9 rE  rE  rE  rE  rE  \t {E → E * B•}\n"
     ]
    }
   ],
   "source": [
    "table = [[\"   \"] * (len(augmented_grammar.terminals)) for i in range(len(states))]\n",
    "terminals = sorted(augmented_grammar.terminals)\n",
    "for situation, action in list(actions.items()):\n",
    "    state_index, terminal = situation\n",
    "    table[state_index][terminals.index(terminal)] = f\"{action[0][0]}{str(action[1])[:2]:2}\"\n",
    "print(\"--\", \" \".join(map(repr, terminals)))\n",
    "for i, row in enumerate(table):\n",
    "    print(f\"{i:2}\", \" \".join(row), \"\\t\", states[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6985c72",
   "metadata": {},
   "source": [
    "### Gotos precomputed\n",
    "We precomputed the actions, why not precompute goto(...) results? We need them for nonterminals to know\n",
    "what state to go when reducing something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "938c432b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 'B'): 2, (0, 'E'): 3, (5, 'B'): 8, (7, 'B'): 9}\n"
     ]
    }
   ],
   "source": [
    "def precompute_gotos(grammar):\n",
    "    states = grammar_states(grammar)\n",
    "    gotos = {}\n",
    "    for i, state in enumerate(states):\n",
    "        for variable in grammar.variables:\n",
    "            next_state = goto(grammar, state, variable)\n",
    "            if next_state:\n",
    "                gotos[i, variable] = states.index(next_state)\n",
    "    return gotos\n",
    "gotos = precompute_gotos(augmented_grammar)\n",
    "print(gotos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb9f57e",
   "metadata": {},
   "source": [
    "### Runtime of the parser\n",
    "Using all the precomputed information we can now write the parser, that uses only numbers/indexes of states, not the states itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb80736b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'E'\n",
      " ├'B'\n",
      " │ ├'E'\n",
      " │ │ ├'B'\n",
      " │ │ │ ├'1'\n",
      " │ ├'+'\n",
      " │ ├'1'\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def parser(actions, gotos, DEBUG=False):\n",
    "    def parse(source):\n",
    "        stack = [(\"$\", 0)]\n",
    "        i, tokens = 0, list(source) + [\"$\"]\n",
    "        while True:\n",
    "            token = tokens[i]\n",
    "            last_token, state = stack[-1]\n",
    "            action = actions[state, token] \n",
    "            if DEBUG: print(stack, \"<<<\", repr(token), \":\", action)\n",
    "            if action[0] == \"shift\":\n",
    "                next_state, i = action[1], i + 1\n",
    "                stack.append(([token], next_state))\n",
    "            elif action[0] == \"reduce\":\n",
    "                variable, size = action[1:]\n",
    "                stack, node = stack[:-size], stack[size:]\n",
    "                next_state = gotos[stack[-1][1], variable]\n",
    "                stack.append(([variable] + [n for n, _ in node], next_state))\n",
    "                #stack.append((variable, next_state))\n",
    "            elif action[0] == \"accept\":\n",
    "                return stack[1][0]\n",
    "            else:\n",
    "                raise Exception(f\"{repr(stack)} <<< {token}\")\n",
    "    return parse\n",
    "\n",
    "def print_ast(ast, offset = 0):\n",
    "    head, children = ast[0], ast[1:]\n",
    "    print(\" │\" * (offset - 1) + \" ├\" * bool(offset) + repr(head))\n",
    "    for child in children:\n",
    "        print_ast(child, offset + 1)\n",
    "\n",
    "parse = parser(actions, gotos)\n",
    "print_ast(parse(\"1+1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06de8078",
   "metadata": {},
   "source": [
    "# THE END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77d6fcdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'E'\n",
      " ├'B'\n",
      " │ ├'E'\n",
      " │ │ ├'B'\n",
      " │ │ │ ├'E'\n",
      " │ │ │ │ ├'B'\n",
      " │ │ │ │ │ ├'1'\n",
      " │ │ │ ├'*'\n",
      " │ │ │ ├'0'\n",
      " │ ├'+'\n",
      " │ ├'1'\n"
     ]
    }
   ],
   "source": [
    "print_ast(parse(\"1*0+1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c37e076e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'E'\n",
      " ├'B'\n",
      " │ ├'1'\n"
     ]
    }
   ],
   "source": [
    "print_ast(parse(\"1\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
